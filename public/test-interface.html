<!DOCTYPE html>
<html>
  <head>
    <title>AI Phone Assistant - Test Interface</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        max-width: 800px;
        margin: 20px auto;
        padding: 20px;
      }
      #status {
        margin: 10px 0;
        padding: 10px;
        border-radius: 4px;
      }
      .connected {
        background-color: #dff0d8;
        color: #3c763d;
      }
      .disconnected {
        background-color: #f2dede;
        color: #a94442;
      }
      #transcript {
        margin-top: 20px;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
        max-height: 300px;
        overflow-y: auto;
      }
      .user-speech {
        color: #2196f3;
      }
      .ai-response {
        color: #4caf50;
      }
      button {
        padding: 10px 20px;
        font-size: 16px;
        cursor: pointer;
      }
      #startCall {
        background-color: #4caf50;
        color: white;
        border: none;
        border-radius: 4px;
      }
      #startCall:disabled {
        background-color: #cccccc;
        cursor: not-allowed;
      }
      #controls {
        margin: 20px 0;
      }
      #audioLevel {
        margin: 10px 0;
        width: 100%;
        height: 20px;
        background-color: #f0f0f0;
      }
      #audioLevelBar {
        height: 100%;
        width: 0%;
        background-color: #4caf50;
        transition: width 0.1s ease;
      }
    </style>
  </head>
  <body>
    <div id="controls">
      <button id="startCall">Start Call</button>
      <button id="endCall" style="display: none">End Call</button>
    </div>
    <div id="status" class="disconnected">Disconnected</div>
    <div id="audioLevel">
      <div id="audioLevelBar"></div>
    </div>
    <div id="transcript"></div>

    <script>
      let ws;
      let mediaRecorder;
      let audioContext;
      let analyser;
      let isCallActive = false;

      const startCallButton = document.getElementById("startCall");
      const endCallButton = document.getElementById("endCall");
      const statusDiv = document.getElementById("status");
      const transcriptDiv = document.getElementById("transcript");
      const audioLevelBar = document.getElementById("audioLevelBar");

      function updateStatus(message, isConnected) {
        statusDiv.textContent = message;
        statusDiv.className = isConnected ? "connected" : "disconnected";
      }

      function addToTranscript(text, isUser) {
        const p = document.createElement("p");
        p.className = isUser ? "user-speech" : "ai-response";
        p.textContent = text;
        transcriptDiv.appendChild(p);
        transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
      }

      async function startCall() {
        try {
          // Update the WebSocket connection to use the /twilio path
          const protocol =
            window.location.protocol === "https:" ? "wss:" : "wss:";
          ws = new WebSocket(
            `${protocol}//${window.location.host}/twilio/connection`
          );

          ws.onopen = () => {
            updateStatus("Connected", true);
            // Send start event similar to Twilio's format
            ws.send(
              JSON.stringify({
                event: "start",
                start: {
                  streamSid: "test-" + Date.now(),
                  callSid: "test-call-" + Date.now(),
                },
              })
            );
          };

          ws.onclose = () => {
            updateStatus("Disconnected", false);
            endCall();
          };

          ws.onerror = (error) => {
            console.error("WebSocket error details:", error);
            updateStatus(
              `Connection error: ${error.message || "Unknown error"}`,
              false
            );
          };

          ws.onmessage = async (event) => {
            const data = JSON.parse(event.data);
            if (data.transcript) {
              addToTranscript(data.transcript, true);
            }
            if (data.response) {
              addToTranscript(data.response, false);
            }
            if (data.audio) {
              // Play audio response
              const audio = new Audio(data.audio);
              await audio.play();
            }
          };

          // Get microphone access
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });

          // Set up audio processing
          audioContext = new AudioContext();
          const source = audioContext.createMediaStreamSource(stream);
          analyser = audioContext.createAnalyser();
          analyser.fftSize = 256;

          source.connect(analyser);

          // Create media recorder
          mediaRecorder = new MediaRecorder(stream);

          mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0 && ws.readyState === WebSocket.OPEN) {
              // Convert blob to array buffer and send
              event.data.arrayBuffer().then((buffer) => {
                // Create a DataView to properly handle the binary data
                const view = new DataView(buffer);
                const floatArray = new Float32Array(
                  Math.floor(buffer.byteLength / 4)
                );

                // Properly convert the buffer to float32 values
                for (let i = 0; i < floatArray.length; i++) {
                  floatArray[i] = view.getFloat32(i * 4, true); // true for little-endian
                }

                ws.send(
                  JSON.stringify({
                    event: "media",
                    media: {
                      payload: Array.from(floatArray),
                    },
                  })
                );
              });
            }
          };

          mediaRecorder.start(100); // Capture in 100ms chunks

          // Start audio level visualization
          visualize();

          isCallActive = true;
          startCallButton.style.display = "none";
          endCallButton.style.display = "inline";
        } catch (error) {
          console.error("Error starting call:", error);
          updateStatus(`Error: ${error.message}`, false);
        }
      }

      function endCall() {
        if (ws) {
          ws.close();
        }
        if (mediaRecorder && mediaRecorder.state !== "inactive") {
          mediaRecorder.stop();
        }
        if (audioContext) {
          audioContext.close();
        }

        isCallActive = false;
        startCallButton.style.display = "inline";
        endCallButton.style.display = "none";
        updateStatus("Disconnected", false);
      }

      function visualize() {
        if (!isCallActive) return;

        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(dataArray);

        // Calculate audio level
        const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
        const level = (average / 256) * 100;

        // Update visual bar
        audioLevelBar.style.width = `${level}%`;

        requestAnimationFrame(visualize);
      }

      startCallButton.onclick = startCall;
      endCallButton.onclick = endCall;

      // Cleanup on page unload
      window.onbeforeunload = () => {
        if (isCallActive) {
          endCall();
        }
      };
    </script>
  </body>
</html>
